{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WoBXc5YihnRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd8bb3c-e9f5-41ab-f102-9b24ab7da195"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IJzuDI_DlWF",
        "outputId": "a490bd3a-1ad7-4081-a1ef-30d7b2fd322d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nibabel.testing import data_path\n",
        "import SimpleITK as sitk\n",
        "from SimpleITK import ResampleImageFilter\n",
        "from google.colab import files\n",
        "import os\n",
        "import pandas as pd\n",
        "import nibabel as nib \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "data_folder = '/content/drive/MyDrive/ISMI_final_proj'\n",
        "validation_pairs = '/content/drive/MyDrive/ISMI_final_proj/pairs_val_training.csv'\n",
        "\n",
        "# Read the CSV file\n",
        "pairs_df = pd.read_csv(validation_pairs)\n",
        "\n",
        "# Iterate through the pairs and perform registration\n",
        "registration_method = sitk.ImageRegistrationMethod()\n",
        "deformation_fields = []"
      ],
      "metadata": {
        "id": "7xOsBdKcDoM4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set interpolator\n",
        "interpolator = sitk.sitkLinear\n",
        "registration_method.SetInterpolator(interpolator)\n",
        "\n",
        "# Set initial transform (if needed)\n",
        "initial_transform = sitk.Transform()\n",
        "registration_method.SetInitialTransform(initial_transform)\n",
        "\n",
        "num_stages = 3\n",
        "\n",
        "for _, pair in pairs_df.iterrows():\n",
        "    fixed_id = pair[0]\n",
        "    moving_id = pair[1]\n",
        "\n",
        "    fixed_image_path = os.path.join(data_folder, f'L2R_Task4_HippocampusMRI_training/Training/img/hippocampus_{fixed_id}.nii.gz')\n",
        "    moving_image_path = os.path.join(data_folder, f'L2R_Task4_HippocampusMRI_training/Training/img/hippocampus_{moving_id}.nii.gz')\n",
        "\n",
        "    fixed_image = sitk.ReadImage(fixed_image_path)\n",
        "    moving_image = sitk.ReadImage(moving_image_path)\n",
        "\n",
        "    fixed_image = sitk.Cast(fixed_image, sitk.sitkFloat32)\n",
        "\n",
        "    # Check the type and dimension of the images\n",
        "    if fixed_image.GetPixelIDTypeAsString() != moving_image.GetPixelIDTypeAsString():\n",
        "        moving_image = sitk.Cast(moving_image, fixed_image.GetPixelID()) #converts pixel type of moving image to match fixed img\n",
        "\n",
        "\n",
        "    if fixed_image.GetSize() != moving_image.GetSize():\n",
        "        raise ValueError(\"Dimension mismatch between fixed and moving images.\")\n",
        "\n",
        "    # Set initial transformation\n",
        "    initial_transform = sitk.CenteredTransformInitializer(\n",
        "        fixed_image, moving_image, sitk.Euler3DTransform(), sitk.CenteredTransformInitializerFilter.MOMENTS\n",
        "    )\n",
        "    registration_method.SetInitialTransform(initial_transform)\n",
        "\n",
        "    # Set registration parameters\n",
        "    registration_method.SetMetricAsMeanSquares()\n",
        "    registration_method.SetOptimizerAsRegularStepGradientDescent(learningRate=0.1, minStep=1e-4, numberOfIterations=100)\n",
        "    registration_method.SetInterpolator(sitk.sitkLinear)\n",
        "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[4, 2, 1])\n",
        "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2, 1, 0])\n",
        "\n",
        "    # Add observer to observe the registration process\n",
        "    registration_method.AddCommand(sitk.sitkIterationEvent, lambda: print(f\"Iteration: {registration_method.GetOptimizerIteration()}\"))\n",
        "\n",
        "    deformation_field = None\n",
        "    moving_image_prev = moving_image\n",
        "\n",
        "    #multistage registration\n",
        "    for stage in range(num_stages):\n",
        "        resampler = ResampleImageFilter()\n",
        "        resampler.SetReferenceImage(fixed_image)\n",
        "\n",
        "        if deformation_field is not None:\n",
        "            # Create a transformation from the deformation field\n",
        "            displacement_field = sitk.Cast(deformation_field, sitk.sitkVectorFloat64)\n",
        "            transform = sitk.DisplacementFieldTransform(displacement_field)\n",
        "            resampler.SetTransform(transform)\n",
        "        resampler.SetInterpolator(sitk.sitkLinear)\n",
        "\n",
        "        # Warp the moving image using the resampler\n",
        "        warped_moving_image = resampler.Execute(moving_image_prev)\n",
        "\n",
        "        # Perform registration with the warped moving image\n",
        "        final_transform = registration_method.Execute(fixed_image, warped_moving_image)\n",
        "\n",
        "        # Compute the deformation field for the current stage\n",
        "        deformation_field = sitk.TransformToDisplacementField(final_transform, sitk.sitkVectorFloat64)\n",
        "\n",
        "    deformation_fields.append(deformation_field)\n",
        "\n",
        "    # Update the moving image for the next pair\n",
        "    moving_image_prev = moving_image\n",
        "\n",
        "# Save the deformation fields\n",
        "#output_folder = os.path.join(data_folder, 'Displacement_Fields_warped')\n",
        "#os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "#for i, deformation_field in enumerate(deformation_fields):\n",
        " #   output_path = os.path.join(output_folder, f\"displacement_field_{i}.nii.gz\")\n",
        "  #  sitk.WriteImage(deformation_field, output_path)"
      ],
      "metadata": {
        "id": "MHUJuhlJD4WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "\n",
        "output_folder = os.path.join(data_folder, 'Displacement_Fields_warped')\n",
        "# Create the output folder for the warped images\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for _, pair in pairs_df.iterrows():\n",
        "    moving_id = pair[1]\n",
        "    moving_image_path = os.path.join(data_folder, f'L2R_Task4_HippocampusMRI_training/Training/img/hippocampus_{moving_id}.nii.gz')\n",
        "    warped_image_path = os.path.join(output_folder, f\"warped_image_{moving_id}.nii.gz\")\n",
        "\n",
        "    # Read the warped image\n",
        "    warped_image = nib.load(warped_image_path)\n",
        "    warped_image_data = warped_image.get_fdata()\n",
        "\n",
        "    # Display the warped image\n",
        "    plt.figure()\n",
        "    plt.imshow(warped_image_data[:, :, warped_image_data.shape[2] // 2], cmap='gray')\n",
        "    plt.title(f\"Warped Image - ID: {moving_id}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Q5jXxDL7IF-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#install packages\n",
        "!pip install SimpleITK==1.2.0\n",
        "!pip install torch==1.4.0+cu92 torchvision==0.5.0+cu92\n",
        "!pip install tqdm==4.30\n",
        "!pip install numpy==1.16.0\n",
        "!pip install pandas==0.23.4\n",
        "!pip install matplotlib==3.0.2\n",
        "!pip install nibabel==2.3.3\n",
        "!pip install threadpoolctl==2.0.0\n",
        "!pip install scipy==1.4.1\n",
        "!pip install evalutils==0.2.3\n",
        "!pip install surface_distance==0.1\n"
      ],
      "metadata": {
        "id": "YMJfX2hVzlVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "id": "OHPmWLYR13qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import argparse\n",
        "sys.path.append('/content/drive/MyDrive/ISMI_final_proj')\n",
        "\n",
        "from blocks import *\n",
        "from model_loader import load_model\n",
        "\n",
        "import os\n",
        "\n",
        "blocks_path = os.path.join(os.getcwd(), 'blocks.py')\n",
        "print(os.path.exists(blocks_path))"
      ],
      "metadata": {
        "id": "j8AGQ8JZAZKq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = Namespace(\n",
        "    arch='my_model',  # Unet\n",
        "    model_abspath='/content/drive/MyDrive/ISMI_final_proj/Theoest model/Hippocampus_registration/Models/Baseline.pth.tar'  # Path to the pretrained model file\n",
        ")\n",
        "kwargs = {}\n"
      ],
      "metadata": {
        "id": "KC7LavQSTt_j"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from my_model import Decoder, Encoder\n",
        "\n",
        "# Define the parameters\n",
        "in_channels = 4  # Number of input channels\n",
        "out_channels = 1  # Number of output channels\n",
        "pool_blocks = 5  # Number of pooling blocks\n",
        "\n",
        "# Define the number of channels in each block (aligned with pool_blocks)\n",
        "channels = [64, 128, 256, 512, 1024, 1024]  # Number of channels in each block\n",
        "\n",
        "# Make sure the length of channels list is pool_blocks + 1\n",
        "assert len(channels) == pool_blocks + 1, \"Invalid number of channels\"\n",
        "\n",
        "last_activation = 'sigmoid'  # Activation function for the last layer\n",
        "activation_type = 'leaky'  # Activation function for other layers\n",
        "instance_norm = False  # Use instance normalization\n",
        "batch_norm = False  # Use batch normalization\n",
        "nb_Convs = [1, 1, 1, 1, 1]  # Number of convolution layers in each block\n",
        "\n",
        "# Create the encoder and decoder\n",
        "encoder = Encoder(pool_blocks, channels, activation_type, in_channels,\n",
        "                  instance_norm, batch_norm, nb_Convs)\n",
        "decoder = Decoder(pool_blocks, channels, out_channels, last_activation,\n",
        "                  activation_type, instance_norm, batch_norm, nb_Convs)\n",
        "\n",
        "# Create the U-Net model\n",
        "model = nn.Sequential(encoder, decoder)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GzMS7Ty8U2SZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "deformation_fields_path = '/content/drive/MyDrive/ISMI_final_proj/Displacement_Fields_warped'\n",
        "\n",
        "# Create an empty list to store the deformation fields\n",
        "deformation_fields = []\n",
        "\n",
        "import os\n",
        "import nibabel as nib\n",
        "\n",
        "for filename in os.listdir(deformation_fields_path):\n",
        "    if filename.startswith('displacement_field_') and filename.endswith('.nii.gz'):\n",
        "        file_path = os.path.join(deformation_fields_path, filename)\n",
        "        deformation_field = nib.load(file_path)\n",
        "        # Perform further processing with the deformation field\n",
        "        image_data = deformation_field.get_fdata()\n",
        "        deformation_fields.append(image_data)  # Add the loaded deformation field to the list\n",
        "\n",
        "# Verify the contents of the deformation_fields list\n",
        "print(\"Number of deformation fields:\", len(deformation_fields))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYpwAzDWT04I",
        "outputId": "70192d44-62e4-484c-b329-824b02213eac"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of deformation fields: 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class DeformationFieldDataset(Dataset):\n",
        "    def __init__(self, deformation_fields):\n",
        "        self.deformation_fields = deformation_fields\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.deformation_fields)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        deformation_field = self.deformation_fields[index]\n",
        "        \n",
        "        # Return the deformation field as the sample\n",
        "        return deformation_field\n",
        "\n",
        "\n",
        "dataset = DeformationFieldDataset(deformation_fields)\n",
        "\n",
        "# Define the batch size for training\n",
        "batch_size = 32\n",
        "\n",
        "# Create the dataloader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "bHVG8G4fZJff"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model (Unet)\n",
        "model = nn.Sequential(encoder, decoder)\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n"
      ],
      "metadata": {
        "id": "d7EhRaYoW1rb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Set the model in training mode\n",
        "model.train()\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 10  #\n",
        "\n",
        "# Iterate over your training data\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_data in dataloader:\n",
        "        # Move the batch data to the device (e.g., GPU)\n",
        "        batch_data = batch_data.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch_data)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = loss_function(outputs, batch_data)  # Adjust the inputs based on your data and task\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the loss or other metrics if desired\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "              .format(epoch+1, num_epochs, step+1, total_steps, loss.item()))\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/ISMI_final_proj/my_model.py')\n"
      ],
      "metadata": {
        "id": "roU72wX2m0-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmqUbGufSgt6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}